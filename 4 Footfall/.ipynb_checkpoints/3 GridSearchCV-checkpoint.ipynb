{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import project functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPS data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = pd.read_parquet('../data output/7 mixed_gps_density_month_day_hour_for_random_forest.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the hex size to work\n",
    "APERTURE_SIZE = 9\n",
    "hex_col = 'hex' + str(APERTURE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra features to gps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_density = pd.read_csv('../data output/1 london_boundary_hex9_total_digi_cnt.csv')\n",
    "diversity = pd.read_csv('../data output/4 london_boundary_hex9_diversity.csv') #,usecols = ['']\n",
    "census = pd.read_csv('../data output/5 london_boundary_hex9_census.csv',usecols = [hex_col,'Population density km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps = gps.merge(poi_density, how='inner', on=hex_col).\\\n",
    "        merge(diversity, how='inner', on=hex_col).\\\n",
    "        merge(census, how='inner', on=hex_col).\\\n",
    "        rename(columns={'total_cnt':'poi_cnt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hex9', 'time_cat', 'day_cat', 'month', 'gps_cnt', 'hex9_lat',\n",
       "       'hex9_lon', 'num_minutes', 'year', 'weekend', 'time_num', 'time_cos',\n",
       "       'time_sin', 'day_sin', 'day_num', 'day_cos', 'poi_cnt', 'shannon',\n",
       "       'Population density km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439544"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1439544.00\n",
       "mean           5.31\n",
       "std           10.48\n",
       "min            1.00\n",
       "25%            1.00\n",
       "50%            3.00\n",
       "75%            6.00\n",
       "max          785.00\n",
       "Name: gps_cnt, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps.gps_cnt.describe().apply(lambda x: format(x, '.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_hot = gps.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "gps_hot = pd.concat([gps_hot, pd.get_dummies(gps[['month']])], axis=1).drop(['month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_test_list = [ #'day_cat','time_cat', # 'country', 'month',\n",
    "                   'weekend',# 'year'\n",
    "                   \"{}_lat\".format(hex_col), \"{}_lon\".format(hex_col) ,#'num_minutes', \n",
    "                   'time_num', 'time_cos', 'time_sin', 'day_num','day_cos',\n",
    "                   'day_sin', 'poi_cnt', 'shannon', 'Population density km']\n",
    "gps_predict_label = 'gps_cnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion for cross-validation over a grid of parameters\n",
    "\n",
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None, verbose=0):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func, verbose=verbose)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds, verbose=verbose)\n",
    "    gs.fit(X, y)\n",
    "    print(\"BEST\", gs.best_params_, gs.best_score_, gs.cv_results_, gs.scorer_)\n",
    "    print(\"Best score: \", gs.best_score_)\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is the values we want to predict\n",
    "y = gps_hot[gps_predict_label].values\n",
    "# OR\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(gps_hot[gps_predict_label])\n",
    "\n",
    "# Convert to numpy array\n",
    "X = gps_hot[gps_test_list].values\n",
    "# OR\n",
    "# Convert to numpy array\n",
    "gps_array = np.array(gps_hot[gps_test_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_features, test_features, train_labels, test_labels =\\\n",
    "#     train_test_split(gps_array, labels, test_size = 0.20) # , random_state = 42\n",
    "\n",
    "#OR\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size = 0.20) # , random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Regression estimator\n",
    "estimator = RandomForestRegressor(n_estimators=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-15.140265639097734, total= 2.3min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-12.570048367987921, total= 2.3min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-13.558498838757975, total= 2.2min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-13.30157270139637, total= 2.3min\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=-12.610344809218118, total= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'max_depth': 50, 'max_features': 'auto', 'n_estimators': 50} -13.436146071291624 {'mean_fit_time': array([133.39105849]), 'std_fit_time': array([2.05557925]), 'mean_score_time': array([2.47728758]), 'std_score_time': array([0.16295654]), 'param_max_depth': masked_array(data=[50],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=['auto'],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 50, 'max_features': 'auto', 'n_estimators': 50}], 'split0_test_score': array([-15.14026564]), 'split1_test_score': array([-12.57004837]), 'split2_test_score': array([-13.55849884]), 'split3_test_score': array([-13.3015727]), 'split4_test_score': array([-12.61034481]), 'mean_test_score': array([-13.43614607]), 'std_test_score': array([0.9347916]), 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([-1.84710562]), 'split1_train_score': array([-2.0059995]), 'split2_train_score': array([-1.92487493]), 'split3_train_score': array([-1.95141498]), 'split4_train_score': array([-1.93127247]), 'mean_train_score': array([-1.9321335]), 'std_train_score': array([0.05120767])} make_scorer(mean_squared_error, greater_is_better=False)\n",
      "Best score:  -13.436146071291624\n"
     ]
    }
   ],
   "source": [
    "# Define a grid of parameters over which to optimize the random forest\n",
    "# We will figure out which number of trees is optimal\n",
    "parameters = {\"n_estimators\": [50],\n",
    "              \"max_features\": [\"auto\"], # [\"auto\",\"sqrt\",\"log2\"]\n",
    "              \"max_depth\": [50]}\n",
    "\n",
    "best = cv_optimize(estimator, parameters, X_train, y_train, n_folds=5, score_func=ftwo_scorer, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on standard predict ################\n",
      "R^2 on training data: 0.9839\n",
      "R^2 on test data:     0.8865\n"
     ]
    }
   ],
   "source": [
    "# Fit the best Random Forest and calculate R^2 values for training and test sets\n",
    "reg=best.fit(X_train, y_train)\n",
    "training_accuracy = reg.score(X_train, y_train)\n",
    "test_accuracy = reg.score(X_test, y_test)\n",
    "print(\"############# based on standard predict ################\")\n",
    "print(\"R^2 on training data: %0.4f\" % (training_accuracy))\n",
    "print(\"R^2 on test data:     %0.4f\" % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 1,  1],\n",
       "       [ 4,  2],\n",
       "       ...,\n",
       "       [ 1,  0],\n",
       "       [ 0,  0],\n",
       "       [ 4, 14]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some of the predictions vs. the real number of pickups\n",
    "# predictions vs. real number of pickups\n",
    "\n",
    "# #log space\n",
    "# np.round(np.power(10,np.column_stack((reg.predict(X_test),y_test))) - 1,decimals=0).astype(int)\n",
    "\n",
    "np.round(np.column_stack((reg.predict(X_test),y_test))- 1,decimals=0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "# # log space\n",
    "# y_pred = np.power(10, reg.predict(X_test)) #OR test_features\n",
    "\n",
    "y_pred =reg.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error units: gps events\n",
      "Mean Absolute Error: 1.932213029944294\n",
      "Mean Squared Error: 12.182301007418971\n",
      "Root Mean Squared Error: 3.490315316331602\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('error units: gps events')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 3.522 \n"
     ]
    }
   ],
   "source": [
    "# Calculate the Root Mean Squared Error\n",
    "rmse = np.sqrt(mean_squared_error(reg.predict(X_test),y_test))\n",
    "print(\"RMSE = %0.3f \" % rmse)\n",
    "\n",
    "# # log space\n",
    "# print(\"RMSE = %0.3f (this is in log-space!)\" % rmse)\n",
    "# print(\"So two thirds of the records would be a factor of less than %0.2f away from the real value.\" % np.power(10,rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('poi_cnt', 0.2511636247085833),\n",
       " ('hex9_lon', 0.16733166676534303),\n",
       " ('hex9_lat', 0.12736566411487638),\n",
       " ('day_num', 0.09474953268196255),\n",
       " ('Population density km', 0.07486840825686361),\n",
       " ('shannon', 0.07478904114511661),\n",
       " ('time_cos', 0.06700665133530055),\n",
       " ('time_num', 0.056847534496115716),\n",
       " ('day_cos', 0.031199206968934464),\n",
       " ('day_sin', 0.027298076606402807),\n",
       " ('time_sin', 0.024745926911198493),\n",
       " ('weekend', 0.0026346660093025877)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most important features?\n",
    "import operator\n",
    "dict_feat_imp = dict(zip(gps_test_list,reg.feature_importances_))\n",
    "\n",
    "sorted_features = sorted(dict_feat_imp.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check pred vs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframes with all possible times (time_data) and all possible locations (loc_data)\n",
    "X = gps_hot.copy()\n",
    "\n",
    "# Columns about time\n",
    "time_cols = list(X.columns.values)\n",
    "time_cols.remove(\"{}_lat\".format(hex_col))\n",
    "time_cols.remove(\"{}_lon\".format(hex_col))\n",
    "\n",
    "# Columns about location\n",
    "loc_cols = [\"{}_lat\".format(hex_col),\"{}_lon\".format(hex_col)]\n",
    "\n",
    "# Unique times\n",
    "time_data = X.drop(loc_cols, axis=1).drop_duplicates()\n",
    "\n",
    "# # # We are only going to look at Monday\n",
    "time_data = time_data[time_data['day_num'] <= 1/7.]\n",
    "\n",
    "# Unique locations\n",
    "loc_data = X.drop(time_cols, axis=1).drop_duplicates()\n",
    "\n",
    "# To reduce memory consumption, we are only predicting for\n",
    "# the region closely around UCL\n",
    "# 51.514138,-0.151663,51.532775,-0.118189\n",
    "loc_data = loc_data[(loc_data[\"{}_lat\".format(hex_col)] > 51.514138) & (loc_data[\"{}_lat\".format(hex_col)] < 51.532775) &\n",
    "                    (loc_data[\"{}_lon\".format(hex_col)] > -0.151663) & (loc_data[\"{}_lon\".format(hex_col)] < -0.118189)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy column to be able to join them together\n",
    "time_data['key'] = 1\n",
    "loc_data['key'] = 1\n",
    "\n",
    "# Merge the time_data and location_data\n",
    "result = pd.merge(time_data, loc_data, on='key').drop(['key'], axis=1)\n",
    "result = result[gps_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the real number of pickups and take care that we can merge it with the predictions,\n",
    "# by also taking the geohash and the timestamp\n",
    "yy = gps_hot[[\"{}_lat\".format(hex_col), \"{}_lon\".format(hex_col),'time_num','day_num','gps_cnt']] # 'day_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions and convert the logarithm to the normal numbers\n",
    "\n",
    "# # log space\n",
    "# result['pred_cnt'] = np.power(10,reg.predict(result)) - 1\n",
    "\n",
    "result['pred_cnt'] = reg.predict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the predictions and the real cnt\n",
    "result = pd.merge(result, yy, how='left', on=['day_num','time_num', \"{}_lat\".format(hex_col), \"{}_lon\".format(hex_col)])#.drop([hex_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_cnt</th>\n",
       "      <th>gps_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045698</th>\n",
       "      <td>10.36</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158770</th>\n",
       "      <td>7.08</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476220</th>\n",
       "      <td>6.58</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609749</th>\n",
       "      <td>10.08</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373234</th>\n",
       "      <td>16.24</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6024964</th>\n",
       "      <td>12.22</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029743</th>\n",
       "      <td>2.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493623</th>\n",
       "      <td>7.06</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480986</th>\n",
       "      <td>40.60</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255130</th>\n",
       "      <td>1.86</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_cnt  gps_cnt\n",
       "1045698     10.36     26.0\n",
       "158770       7.08    116.0\n",
       "8476220      6.58    159.0\n",
       "6609749     10.08     10.0\n",
       "6373234     16.24     45.0\n",
       "6024964     12.22     43.0\n",
       "7029743      2.20      1.0\n",
       "2493623      7.06    108.0\n",
       "4480986     40.60     59.0\n",
       "3255130      1.86     13.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[~result.gps_cnt.isnull()][['pred_cnt','gps_cnt']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.094730e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.396743e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.239757e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.980000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.792000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.872000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.344800e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  1.094730e+07\n",
       "mean   3.396743e+01\n",
       "std    6.239757e+01\n",
       "min    0.000000e+00\n",
       "25%    5.980000e+00\n",
       "50%    1.792000e+01\n",
       "75%    3.872000e+01\n",
       "max    7.344800e+02"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(abs(result.pred_cnt - result.gps_cnt)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lefteris/anaconda3/envs/geoindex/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False,  True,  True,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "# itrain, itest = train_test_split(range(gps_hot.shape[0]), train_size=0.8)\n",
    "# mask=np.ones(gps_hot.shape[0], dtype='int')\n",
    "# mask[itrain]=1\n",
    "# mask[itest]=0\n",
    "# mask = (mask==1)\n",
    "# mask[:10]\n",
    "\n",
    "\n",
    "#2\n",
    "\n",
    "# # Split off the features\n",
    "# X = gps_hot[gps_test_list]\n",
    "\n",
    "# # Split off the target (which will be the logarithm of the number of cnts (+1))\n",
    "# # y =np.log10(gps_hot[gps_predict_label]+1) #gps['cnt']\n",
    "\n",
    "# y = gps_hot[gps_predict_label].values\n",
    "\n",
    "\n",
    "#3\n",
    "\n",
    "# X_train, X_test, y_train, y_test = X[mask], X[~mask], y[mask], y[~mask]\n",
    "# n_samples = X_train.shape[0]\n",
    "# n_features = X_train.shape[1]\n",
    "# print(X_train.shape)\n",
    "# max_samples = 1000000\n",
    "\n",
    "# if X_train.shape[0] > max_samples:\n",
    "#     rows = random.sample(list(X_train.index), max_samples)\n",
    "#     X_train = X_train.ix[rows]\n",
    "#     y_train = y_train.ix[rows]\n",
    "# print(X_train.shape)\n",
    "\n",
    "# X_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
